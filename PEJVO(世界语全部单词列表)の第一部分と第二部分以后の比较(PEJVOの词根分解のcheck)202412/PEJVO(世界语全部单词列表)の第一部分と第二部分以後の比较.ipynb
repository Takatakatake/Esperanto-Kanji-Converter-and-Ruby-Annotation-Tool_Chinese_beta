{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a09853a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32045"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ファイルを開いて読み込む\n",
    "words_dict={}\n",
    "length=2\n",
    "with open('PEJVO(世界语全部单词列表)の第一部分について、词尾(a,i,u,e,o,n等)をcutし、comma(,)で隔てて品詞と併せて记录した列表.txt', 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        # 改行を削除\n",
    "        line = line.strip()\n",
    "        # カンマで分割して最初の部分を取得\n",
    "        original_word = line.split(',')[0]\n",
    "        # スラッシュを取り除いた単語をキーとする\n",
    "        key_word = original_word.replace('/', '')\n",
    "        # 辞書に追加\n",
    "        if len(key_word)>=length:\n",
    "            if key_word in words_dict:\n",
    "                if len(original_word+'/')>len(words_dict[key_word]):##より長いほうが、より正しく語根分解できている可能性が高い。\n",
    "                    words_dict[key_word] = original_word+'/'\n",
    "            else:\n",
    "                words_dict[key_word] = original_word+'/'\n",
    "\n",
    "with open('PEJVO(世界语全部单词列表)の第二部分以後について、词尾(a,i,u,e,o,n等)をcutし、comma(,)で隔てて品詞と併せて记录した列表.txt', 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        # 改行を削除\n",
    "        line = line.strip()\n",
    "        # カンマで分割して最初の部分を取得\n",
    "        original_word = line.split(',')[0]\n",
    "        # スラッシュを取り除いた単語をキーとする\n",
    "        key_word = original_word.replace('/', '')\n",
    "        # 辞書に追加\n",
    "        if len(key_word)>=length:\n",
    "            if key_word in words_dict:\n",
    "                if len(original_word+'/')>len(words_dict[key_word]):##より長いほうが、より正しく語根分解できている可能性が高い。\n",
    "                    words_dict[key_word] = original_word+'/'\n",
    "            else:\n",
    "                words_dict[key_word] = original_word+'/'\n",
    "# 結果を確認\n",
    "\n",
    "\n",
    "# for key, value in dict(list(words_dict.items())[:10]).items():\n",
    "#     print(f\"{key}: {value}\")\n",
    "len(words_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bef06924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31933 2371\n"
     ]
    }
   ],
   "source": [
    "# ファイルを開いて読み込む\n",
    "words_dict1={}\n",
    "length=2\n",
    "with open('PEJVO(世界语全部单词列表)の第一部分について、词尾(a,i,u,e,o,n等)をcutし、comma(,)で隔てて品詞と併せて记录した列表.txt', 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        # 改行を削除\n",
    "        line = line.strip()\n",
    "        # カンマで分割して最初の部分を取得\n",
    "        original_word = line.split(',')[0]\n",
    "        # スラッシュを取り除いた単語をキーとする\n",
    "        key_word = original_word.replace('/', '')\n",
    "        # 辞書に追加\n",
    "        if len(key_word)>=length:\n",
    "            if key_word in words_dict1:\n",
    "                if len(original_word+'/')>len(words_dict1[key_word]):##より長いほうが、より正しく語根分解できている可能性が高い。\n",
    "                    words_dict1[key_word] = original_word+'/'\n",
    "            else:\n",
    "                words_dict1[key_word] = original_word+'/'\n",
    "            \n",
    "words_dict2={}\n",
    "with open('PEJVO(世界语全部单词列表)の第二部分以後について、词尾(a,i,u,e,o,n等)をcutし、comma(,)で隔てて品詞と併せて记录した列表.txt', 'r', encoding='utf-8') as file:\n",
    "    for line in file:\n",
    "        # 改行を削除\n",
    "        line = line.strip()\n",
    "        # カンマで分割して最初の部分を取得\n",
    "        original_word = line.split(',')[0]\n",
    "        # スラッシュを取り除いた単語をキーとする\n",
    "        key_word = original_word.replace('/', '')\n",
    "        # 辞書に追加\n",
    "        if len(key_word)>=length:\n",
    "            if key_word in words_dict2:\n",
    "                if len(original_word+'/')>len(words_dict2[key_word]):##より長いほうが、より正しく語根分解できている可能性が高い。\n",
    "                    words_dict2[key_word] = original_word+'/'\n",
    "            else:\n",
    "                words_dict2[key_word] = original_word+'/'\n",
    "\n",
    "print(len(words_dict1),len(words_dict2))     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "370828f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('No.10000_500000.txt', 'r', encoding='utf-8') as file:##漢字置換時に用いる\"place holder\"ファイルを予め読み込んでおく。\n",
    "    loaded_strings = [line.strip() for line in file]\n",
    "\n",
    "replacements1=[]\n",
    "for idx, (i, j) in enumerate(words_dict1.items()):\n",
    "    replacements1.append([i, j, loaded_strings[idx]])\n",
    "replacements1= sorted(replacements1, key=lambda x: len(x[0]), reverse=True)##(置換順序の数字の大きさ順にソート!)\n",
    "\n",
    "replacements2=[]\n",
    "for idx, (i, j) in enumerate(words_dict2.items()):\n",
    "    replacements2.append([i, j, loaded_strings[idx]])\n",
    "replacements2= sorted(replacements2, key=lambda x: len(x[0]), reverse=True)##(置換順序の数字の大きさ順にソート!)\n",
    "\n",
    "replacements=[]\n",
    "for idx, (i, j) in enumerate(words_dict.items()):\n",
    "    replacements.append([i, j, loaded_strings[idx]])\n",
    "replacements= sorted(replacements, key=lambda x: len(x[0]), reverse=True)##(置換順序の数字の大きさ順にソート!)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "888faf0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##置換に用いる関数。正規表現、C++など様々な形式の置換を試したが、pythonで'place holder'を用いる形式の置換が、最も処理が高速であった。(しかも大変シンプルでわかりやすい。)\n",
    "def safe_replace(text, replacements):\n",
    "    valid_replacements = {}\n",
    "    # 置換対象(old)を'place holder'に一時的に置換\n",
    "    for old, new, placeholder in replacements:\n",
    "        if old in text:\n",
    "            text = text.replace(old, placeholder)\n",
    "            valid_replacements[placeholder] = new# 後で置換後の文字列(new)に置換し直す必要がある'place holder'を辞書(valid_replacements)に記録しておく。\n",
    "    #'place holder'を置換後の文字列(new)に置換)\n",
    "    for placeholder, new in valid_replacements.items():\n",
    "        text = text.replace(placeholder, new)\n",
    "    return text\n",
    "\n",
    "def safe_replace2(text, replacements):\n",
    "    valid_replacements = {}\n",
    "    # 置換対象(old)を'place holder'に一時的に置換\n",
    "    for old, new, placeholder in replacements:\n",
    "        if old in text:\n",
    "            text = text.replace(old, placeholder)\n",
    "            valid_replacements[placeholder] = new# 後で置換後の文字列(new)に置換し直す必要がある'place holder'を辞書(valid_replacements)に記録しておく。\n",
    "    #'place holder'を置換後の文字列(new)に置換)\n",
    "    for placeholder, new in valid_replacements.items():\n",
    "        text = text.replace(placeholder, '/'+new+'/')\n",
    "    return text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eea7dd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ファイルに書き出す\n",
    "# with open('replacements1.txt', 'w', encoding='utf-8') as file:\n",
    "#     for item in replacements1:\n",
    "#         # 各サブリストをカンマで結合し、ファイルに一行として書き込む\n",
    "#         line = ','.join(item)\n",
    "#         file.write(line + '\\n')\n",
    "\n",
    "# with open('replacements2.txt', 'w', encoding='utf-8') as file:\n",
    "#     for item in replacements2:\n",
    "#         # 各サブリストをカンマで結合し、ファイルに一行として書き込む\n",
    "#         line = ','.join(item)\n",
    "#         file.write(line + '\\n')\n",
    "\n",
    "# with open('replacements.txt', 'w', encoding='utf-8') as file:\n",
    "#     for item in replacements:\n",
    "#         # 各サブリストをカンマで結合し、ファイルに一行として書き込む\n",
    "#         line = ','.join(item)\n",
    "#         file.write(line + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e92943",
   "metadata": {},
   "source": [
    "replaceした方,originalの順番"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48f2c672",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('第一部分から見た第二部分以後の词根分解の不一致.txt', 'w', encoding='utf-8') as file:\n",
    "    for key1,value1 in words_dict2.items():\n",
    "        # filtered_replacements = [item for item in replacements1]## if item[0] != key1\n",
    "        # filtered_keys = [x for x in sorted_keys if x != key1]\n",
    "        text = safe_replace2(key1, replacements1)\n",
    "        text2 = text.replace('///','/').replace('//','/')\n",
    "        if text2.rstrip('/').lstrip('/')!=value1.rstrip('/').lstrip('/'):\n",
    "            file.write(text2+',  '+value1+'\\n')\n",
    "            #print(text.replace('//','/'),value1)###value1がオリジナルで、恐らくは正しい可能性が高い方\n",
    "            # fuicchi.append([text,value1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eee9d87c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('第二部分以後から見た第一部分の词根分解の不一致.txt', 'w', encoding='utf-8') as file:\n",
    "    for key1,value1 in words_dict1.items():\n",
    "        # filtered_replacements = [item for item in replacements2]## if item[0] != key1\n",
    "        # filtered_keys = [x for x in sorted_keys if x != key1]\n",
    "        text = safe_replace2(key1, replacements2)\n",
    "        text2 = text.replace('///','/').replace('//','/')\n",
    "        if text2.rstrip('/').lstrip('/')!=value1.rstrip('/').lstrip('/'):\n",
    "            file.write(text2+',  '+value1+'\\n')\n",
    "            #print(text.replace('//','/'),value1)###value1がオリジナルで、恐らくは正しい可能性が高い方\n",
    "            # fuicchi.append([text,value1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0883bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('PEJVO(世界语全部单词列表)自身から見た自身の词根分解の不一致.txt', 'w', encoding='utf-8') as file:\n",
    "    for key1,value1 in words_dict.items():\n",
    "        filtered_replacements = [item for item in replacements]## if item[0] != key1\n",
    "        # filtered_keys = [x for x in sorted_keys if x != key1]\n",
    "        text = safe_replace2(key1, filtered_replacements)\n",
    "        text2 = text.replace('///','/').replace('//','/')\n",
    "        if text2.rstrip('/').lstrip('/')!=value1.rstrip('/').lstrip('/'):\n",
    "            file.write(text2+',  '+value1+'\\n')\n",
    "            #print(text.replace('//','/'),value1)###value1がオリジナルで、恐らくは正しい可能性が高い方\n",
    "            # fuicchi.append([text,value1])\n",
    "##ほぼゼロ！！\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6a54774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('fuicchi_self_without_self.txt', 'w', encoding='utf-8') as file:\n",
    "#     for key1,value1 in words_dict.items():\n",
    "#         filtered_replacements = [item for item in replacements if item[0] != key1]## if item[0] != key1\n",
    "#         # filtered_keys = [x for x in sorted_keys if x != key1]\n",
    "#         text = safe_replace2(key1, filtered_replacements)\n",
    "#         text2 = text.replace('///','/').replace('//','/')\n",
    "#         if text2.rstrip('/').lstrip('/')!=value1.rstrip('/').lstrip('/'):\n",
    "#             file.write(text2+',  '+value1+'\\n')\n",
    "            #print(text.replace('//','/'),value1)###value1がオリジナルで、恐らくは正しい可能性が高い方\n",
    "            # fuicchi.append([text,value1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
